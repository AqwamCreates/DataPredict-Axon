# [API Reference](../API.md) - ReinforcementLearningModels

## Constructors

### new

```

ReinforcementLearningModels.new{categoricalUpdateFunction: function, diagonalGaussianUpdateFunction: function, episodeUpdateFunction: function}: ReinforcementLearningModel

```

#### Parameters:

* categoricalUpdateFunction: The update function for categorical actions.

* diagonalGaussianUpdateFunction: The update function for diagonal gaussian actions.

* episodeUpdateFunction: The episode function for all actions.

* resetFunction: The reset function for the reinforcement learning model.

#### Returns:

* ReinforcementLearningModel: The reinforcement learning model that is generated by the constructor.

### MonteCarloControl

```

ReinforcementLearningModels.MonteCarloControl{Model: function, WeightContainer: WeightContainer, discountFactor:  number}: ReinforcementLearningModel

```

#### Parameters:

* Model: The model to be used for outputing actions.

* WeightContainer: The weight container to be used to update the weight tensors.

* discountFactor: The higher the value, the more likely it focuses on long-term outcomes. The value must be set between 0 and 1. [Default: 0.95]

#### Returns:

* ReinforcementLearningModel: The reinforcement learning model that is generated by the constructor.

### OffPolicyMonteCarloControl

```

ReinforcementLearningModels.OffPolicyMonteCarloControl{Model: function, WeightContainer: WeightContainer, targetPolicyFunction: string, discountFactor:  number}: ReinforcementLearningModel

```

#### Parameters:

* Model: The model to be used for outputing actions.

* WeightContainer: The weight container to be used to update the weight tensors.

* targetPolicyFunction: A function that defines the target policy used to select actions. The policy should be based on the current Q-values (or state-action values). This function determines how the agent chooses actions based on its current knowledge. Available options include:

  * Greedy: Selects the action with the highest Q-value for a given state. This is typically the optimal policy, assuming the Q-values are accurate.

  * Softmax: Selects actions probabilistically, where actions with higher Q-values are more likely to be chosen. The probability of selecting an action is determined by a temperature parameter that controls the exploration-exploitation trade-off.

  * StableSoftmax: The more stable option of Softmax (Default)

* discountFactor: The higher the value, the more likely it focuses on long-term outcomes. The value must be set between 0 and 1. [Default: 0.95]

#### Returns:

* ReinforcementLearningModel: The reinforcement learning model that is generated by the constructor.
